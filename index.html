<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Reproduceable software experiments through semantic configurations</title>
  <link rel="stylesheet" media="screen" href="styles/screen.css">
  <link rel="stylesheet" media="print"  href="styles/print.css">
  <link href="https://fonts.googleapis.com/css?family=Ubuntu+Mono" rel="stylesheet">
</head>
<body prefix="cc: https://creativecommons.org/ns# rdfs: http://www.w3.org/2000/01/rdf-schema# opmw: http://www.opmw.org/ontology/">
  <header>
  <h1 id="reproduceable-software-experiments-through-semanticconfigurations">Reproduceable software experiments through semantic configurations</h1>

  <ul id="authors">
    <li><a href="http://www.rubensworks.net/" typeof="http://xmlns.com/foaf/0.1/Person" resource="http://www.rubensworks.net/#me">Ruben Taelman</a><a href="#idlab"><sup>1</sup></a></li>
    <li><a href="#" typeof="http://xmlns.com/foaf/0.1/Person" resource="https://data.verborgh.org/people/joachim_van_herwegen">Joachim Van Herwegen</a><a href="#idlab"><sup>1</sup></a></li>
    <li><a href="http://csarven.ca/" typeof="http://xmlns.com/foaf/0.1/Person" resource="http://csarven.ca/#i">Sarven Capadisli</a><a href="#eisd"><sup>2</sup></a></li>
    <li><a href="https://ruben.verborgh.org/" typeof="http://xmlns.com/foaf/0.1/Person" resource="https://ruben.verborgh.org/profile/#me">Ruben Verborgh</a><a href="#idlab"><sup>1</sup></a></li>
  </ul>

  <ul id="affiliations">
    <li id="idlab"><sup>1</sup>IDLab,
          Department of Electronics and Information Systems,
          Ghent University – imec</li>
    <li id="eisd"><sup>2</sup>Enterprise Information Systems Department,
          University of Bonn</li>
  </ul>

  <section id="abstract">
    <h2>Abstract</h2>
    <!-- Context      -->
    <p>The scientific process requires reproducible experiments and findings
to foster trust and accountability.
Within computer science engineering,
reproducing experiments involves setting up
the exact same software with the same benchmarks and test data,
which often requires non-trivial manual work.
<!-- Need         -->
Unfortunately,
many research articles ambiguously refer to software by name only,
leaving out crucial details such as module and dependency version numbers
or the configuration of the individual components.
<!-- Task         -->
To this end, we created vocabularies
for the semantic description of software components and their configuration,
which can be published as Linked Data alongside experimental results.
We implemented a dependency injection framework
to accurately instantiate these described experimental configurations.
<!-- Object       -->
This article discusses the approach and its application,
and explains with a use case
how to publish experiments and their software configurations on the Web.
<!-- Findings     -->
In order to enable semantic interlinking between configurations and modules,
we published the metadata of all 480,000+ JavaScript libraries on npm
as 174,000,000+ RDF triples.
<!-- Conclusion   -->
Through our work,
research articles can refer by URL
to fine-grained, instantiatable descriptions of experimental setups,
completing the provenance chain from
specifications to implementations, dependencies, and configurations
all the way to experimental results.
This ultimately brings faster and more accurate reproductions of experiments,
and facilitates the evaluation of new research contributions.
<!-- Perspectives -->
Moreover, this work can serve other use cases,
such as general software instantiation outside of experiments,
and reasoning or querying over software configuration metadata.</p>

  </section>

</header>

<main>
  <section id="introduction">
    <h2>Introduction</h2>

    <p>A large number of computer science articles describe experimental software evaluations,
but many of them refer to that software only by name or version number.
This information is insufficient for readers
to understand which <em>exact</em> version of the software,
which versions of its <em>dependencies</em>,
and which detailed <em>configuration</em> of the software’s components
has obtained the reported results.
Therefore, potential users do not necessarily obtain the correct software installation
that will behave according to the article’s conclusions.
Moreover, other researchers might fail
in reproducing the same results
because of differences in any such aspects.</p>

    <p>As <a property="http://purl.org/spar/cito/providesQuotationFor" href="http://www-stat.stanford.edu/~donoho/Reports/1995/wavelab.pdf">Claerbout’s Principle</a> <a class="reference" href="#ref-1">[1]</a> explains,
<q>an article about computational science in a scientific publication
is not the scholarship itself, it is merely <strong>advertising</strong> of the scholarship.
The actual scholarship is the complete software development environment
and the complete set of instructions which generated the figures.</q>
This stresses the importance of reproducibility,
and essentially mandates a detailed description
of the executed experiment,
all of the involved artefacts and actors,
and the processing of the retrieved data.</p>

    <p>Using <a property="http://purl.org/spar/cito/citesAsAuthority" href="https://www.w3.org/DesignIssues/LinkedData.html">Linked Data</a> <a class="reference" href="#ref-2">[2]</a>
to publish such descriptions provides two immediate benefits:
the experimental setup and parts thereof can be <em>identified by IRIs</em>,
and their details can be retrieved by <em>dereferencing those IRIs</em>.
Therefore, if research articles complement their textual explanation of an experiment
with the IRI of the full setup, reproducibility is strongly facilitated.
Moreover, the IRIs of the entire experiment or its parts
can be reused in other articles or experiments
to unambiguously refer to the same conditions.
<a href="#description-diagram">Fig. 1</a> illustrates how this leads to a chain of provenance
from the research article to the data
and the experiment that generates it,
as well as all aspects surrounding that experiment.</p>

    <figure id="description-diagram">
<img src="description-diagram.svg" alt="[description diagram]" />
<figcaption>
        <p><span class="label">Fig. 1:</span> A <em>research article</em> is based on <em>result data</em>,
which are the outcomes of an <em>experiment</em>.
The experiment in turn also has (multiple) provenance chains,
and this article focuses on <em>software configurations</em> and <em>software modules</em>.</p>
      </figcaption>
</figure>

    <p>In this article,
we focus on the description of <em>software configurations</em> and <em>software modules</em>,
such that an evaluated software setup
can be referred to unambiguously by an IRI.
We further facilitate the reproduction of experiments
through a mechanism that automatically <em>instantiates</em> the software configuration
based on its Linked Data description.
Our contributions are the following:</p>

    <ul>
      <li>the RDF-based description of <strong>software modules</strong>,
applied to the 480,000+ bundles of <a href="https://www.npmjs.com/">npm</a> (Node.js);</li>
      <li>the RDF-based description of <strong>available components</strong> within software modules;</li>
      <li>the RDF-based description of a <strong>precise configuration</strong> of software modules;</li>
      <li>the <strong>automated instantiation</strong> of such a configuration;</li>
      <li>a <strong>use case</strong> explaining the usage of the resulting Linked Data
in scientific articles.</li>
    </ul>

    <p>This article is structured as follows.
In <a href="#related-work">Section 2</a>, we discuss related work.
<a href="#describing-modules">Section 3</a> introduces the semantic description of software modules.
Next, <a href="#describing-components">Section 4</a> discusses a semantic description of software components and configurations,
followed by the introduction of a dependency injection framework that can instantiate these in <a href="#instantiating">Section 5</a>.
<a href="#use-case">Section 6</a>, describes a use case where we apply software descriptions
to an experimental evaluation.
Finally, we discuss our conclusions and future work in <a href="#conclusion">Section 7</a>.</p>

  </section>

  <section id="related-work">
    <h2>Related Work</h2>

    <p>In this section, we discuss related work on the reproducibility of scientific experiments in scholarly articles,
ontologies for describing these experiments, and dependency injection as a design principle in experimental software.</p>

    <h3 id="reproducibility-of-software-experiments">Reproducibility of software experiments</h3>
    <p>In order to better keep track of experiments and minimise information loss at CERN, <a property="http://purl.org/spar/cito/citesForInformation" href="https://www.w3.org/History/1989/proposal.html">Information Management: A Proposal</a> <a class="reference" href="#ref-3">[3]</a>, recommends a system (WWW) to address questions like <q>Where is this module used? Who wrote this code? Which systems depend on this device?</q>. We contend that the vision to link information systems in the domain of scientific experiments and scholarly articles is not fully realized on the Web. Identifiable parts of experiments, workflows, as well as the articles which refer to them, still predominantly require human intervention and interpretation, and thereby leaving deterministic reproducibility an open problem on the Web. Our work focuses on improving the state of <q>black box</q> science in particular to experiments using software from the <cite>node package manager</cite>.</p>

    <p>In <a property="http://purl.org/spar/cito/cites" href="http://eprints.sztaki.hu/8625/1/Banati_241_2985874_ny.pdf">four-level provenance</a> <a class="reference" href="#ref-4">[4]</a>, authors show that infrastructural, environmental, workflow and data provenance, are needed to achieve reproducibility of scientific workflows.
The information captured at different levels and quality enables different levels of reproducibility or repeatability.
While our work conceptually grounded on the same levels, we describe our concrete work on globally identifiable and semantic descriptions of software modules and configurations.</p>

    <p>With the goal of improving the way dataset-based software evaluations are performed in the Semantic Web,
<a property="http://purl.org/spar/cito/cites" href="http://laurensrietveld.nl/pdf/lodlab.pdf">LOD Lab</a> <a class="reference" href="#ref-5">[5]</a> was introduced.
It offers a service to simplify software evaluation
against a large amount of Linked Datasets.
This was done because (Semantic Web) experiments are typically done using only a few datasets,
since handling them requires significant manual labor.
This service not only makes it easier for researchers to <em>develop</em> experiments,
it also makes it easier for others to <em>reproduce</em> these experiments,
because the manual phase of dataset setup is simplified or even removed.
While reusability of datasets is one aspect of experiment reproducibility,
our work focuses on reusability of software within experiments, and replication of the environment.</p>

    <h3 id="ontologies-and-vocabularies-for-describing-experiments">Ontologies and vocabularies for describing experiments</h3>
    <p>The <a property="http://purl.org/spar/cito/citesAsAuthority" href="https://www.w3.org/TR/prov-o/">PROV Ontology</a> <a class="reference" href="#ref-6">[6]</a> is a domain-independent ontology to capture provenance information about entities, activities, and agents involved in producing data. <a property="http://purl.org/spar/cito/citesAsAuthority" href="http://www.opmw.org/model/OPMW/">The OPMW-PROV Ontology</a> <a class="reference" href="#ref-7">[7]</a> is an ontology for describing abstract and executable workflows. It extends PROV-O and the <a property="http://purl.org/spar/cito/citesAsAuthority" href="http://vocab.linkeddata.es/p-plan/">P-PLAN Ontology</a> <a class="reference" href="#ref-8">[8]</a> which is designed to represent scientific processes. The <a property="http://purl.org/spar/cito/citesAsAuthority" href="https://www.w3.org/TR/vocab-data-cube/">RDF Data Cube Vocabulary</a> <a class="reference" href="#ref-9">[9]</a> enables defining and publishing multi-dimensional data structures and observations.
<a property="http://purl.org/spar/cito/citesAsAuthority" href="http://rdf-vocabulary.ddialliance.org/discovery.html">DDI-RDF Discovery Vocabulary</a> <a class="reference" href="#ref-10">[10]</a> is a vocabulary for publishing metadata about research and survey data</p>

    <p><a property="http://purl.org/spar/cito/cites" href="https://doi.org/10.1016/j.websem.2015.01.003">Workflow-Centric Research Objects</a> <a class="reference" href="#ref-11">[11]</a> realises a suite of ontologies with the <cite><a href="https://w3id.org/ro/">Wf4Ever Research Object Model</a></cite> based on empirical analysis of workflow decay and repair in order to improve scientific workflow preservation requirements. It has the means to aggregate or bundle resources like workflows, provenance of executions, publications and datasets. <a href="">Ontologies for Describing the Context of Scientific Experiment Processes</a> compliments the Research Objects model with the <cite><a href="http://www.timbusproject.net/portal/publications/ontologies/">TIMBUS Context Model</a></cite> by process preservation. Its <q>context can range from immediate and local aspects such as the software and hardware supporting the process, to aspects such as the organisation the process is executed in, the people involved, service providers, and even laws and regulations</q></p>

    <p><a property="http://purl.org/spar/cito/cites" href="http://svn.aksw.org/papers/2015/SEMANTICS_LDWPO/public.pdf">LODFlow</a> <a class="reference" href="#ref-12">[12]</a> proposes the <cite><a href="https://github.com/AKSW/ldwpo">Linked Data Workflow Project Ontology</a></cite> to describe and plan workflows, tool configurations, and reporting.
Tool specifications and their configurations in LODFlow workflows are described declaratively by a human user without a prescribed schema.
Such descriptions are however interpretive in that any given tool is subject to having multiple descriptions by different users.
In contrast to the human-driven descriptions, our work both enables and accelerates the generation of machine-driven Linked Data descriptions of software modules, their components, as well as their configurations to be uniformly created.
Consequently, this makes it possible to accurately describe and instantiate software experiments that can be reused and compared with unambiguously.</p>

    <h3 id="related-work-dependency-injection">Dependency injection</h3>

    <p><a property="http://purl.org/spar/cito/cites" href="http://dx.doi.org/10.1002/smr.257"><em>Separation of concerns</em></a> <a class="reference" href="#ref-13">[13]</a> is a software design principle in which software is
split into separate components, each having their own separate task.
Fowler defines a <a property="http://purl.org/spar/cito/providesQuotationFor" href="https://martinfowler.com/articles/injection.html">software component</a> <a class="reference" href="#ref-14">[14]</a> as
<q>a glob of software that’s intended to be used, without change, by an application that is out of the control of the writers of the component</q>.
This design principle is especially useful for experimental software,
because it improves the flexibility to, for instance,
compare different implementations of an algorithm
by plugging them into a larger piece of software.</p>

    <p>Programmers traditionally interact with a library of components
by calling its functionality from within their own code.
In that case, the developed software module defines the flow of control.
In contrast, with <a property="http://purl.org/spar/cito/cites" href="https://martinfowler.com/bliki/InversionOfControl.html"><em>Inversion of Control</em></a> <a class="reference" href="#ref-15">[15]</a><a class="reference" href="#ref-16">[16]</a>,
an external component framework defines this flow:
programmers write code such that it can be called by the framework.
<a property="http://purl.org/spar/cito/cites" href="https://martinfowler.com/articles/injection.html">Dependency Injection</a> <a class="reference" href="#ref-14">[14]</a> is a form of Inversion of Control where components
are injected into other components by an <em>assembler</em>.
Experimental software benefits from this paradigm,
because it allows different components to be defined and injected independently.</p>

    <p>Dependency injection requires a <em>configuration phase</em>
to describe how components need to be wired together,
and an <em>injection phase</em> to perform the actual instantiation.
Frameworks such as <a href="https://projects.spring.io/spring-framework/">Spring</a>
facilitate configuration by specifying it declaratively in a configuration file.
That way, a specific software configuration can be instantiated
by merely describing it in XML or JSON.
These configuration files, however,
can not always be reused outside the scope of a particular project.
Furthermore, different mechanisms are used
to capture additional information needed for the instantiation,
such as module dependencies and their version numbers.
There is no interoperability between these configuration files,
and they cannot easily be combined into a detailed description
of the exact software used.</p>

    <p>To that end, we introduce RDF-based software dependency configurations
(<a href="#describing-components">Section 4</a>)
that exactly capture the used modules and dependencies
(<a href="#describing-modules">Section 3</a>).
The resulting description can then be published on the Web as Linked Data,
for instance, as part of the description of an experimental evaluation
(<a href="#use-case">Section 6</a>).
Furthermore, we implemented a framework
that can instantiate such software descriptions
directly from the Web
(<a href="#instantiating">Section 5</a>).</p>

  </section>

  <section id="describing-modules">
    <h2>Describing software modules</h2>

    <p>There are several levels of granularity on which software can be described,
going from a high-level package overview to a low-level description of the actual code.
In descriptions, we can use several of these layers,
depending on the context and the requirements.
Drilling down from the top to the bottom, we have the following layers:</p>

    <ul>
      <li>a <strong>bundle</strong> is a container
 with metadata about the software and its functionality
 across different points in time.
 An example is <a href="https://linkedsoftwaredependencies.org/bundles/npm/n3">the <em>N3.js</em> library</a>.</li>
      <li>a <strong>module</strong> or <em>version</em> is a concrete software package
 and an implementation of a bundle.
 <a href="https://linkedsoftwaredependencies.org/bundles/npm/n3/0.10.0"><em>N3.js 0.10.0</em></a> is a module.</li>
      <li>a <strong>component</strong> is a specific part of a module 
 that can be called in a certain way with a certain set of parameters.
 The <a href="https://github.com/RubenVerborgh/N3.js/blob/v0.10.0/lib/N3Parser.js"><em>N3.js 0.10.0 Parser</em></a> is a component.</li>
    </ul>

    <p>Within this section, we will focus on bundles and modules,
while components are described more in-depth in <a href="#describing-components">Section 4</a>.</p>

    <h3 id="node-package-manager-npm">Node Package Manager (npm)</h3>
    <p>An example of a large collection of bundles and modules is the npm library.
It contains over 480,000 JavaScript libraries,
all with their own features and requirements.
Using our terminology,
an npm package is a bundle,
while a specific version of such a package is a module.
The bundle contains the description of the project together with all its versions,
while a module contains the specific dependencies and a link to the actual implementation.</p>

    <p>All this npm data is stored in a <a href="http://couchdb.apache.org/">CouchDB</a>
<a href="https://registry.npmjs.org/">instance</a> with one entry per bundle.
This corresponds to the metadata, added by the package developer in a <a href="https://docs.npmjs.com/files/package.json"><code>package.json</code></a> file,
with additional metadata automatically added by the npm publishing process.
To be able to uniquely identify software components and,
more importantly, interlink software components,
we converted the JSON metadata provided by the npm registry to RDF,
for which we set up a <a href="https://github.com/LinkedSoftwareDependencies/npm-extraction-server" class="mandatory" data-link-text="https:/​/​github.com/​LinkedSoftwareDependencies/​npm-​extraction-​server">server</a>.</p>

    <h3 id="interpreting-packagejson-using-json-ld">Interpreting package.json using JSON-LD</h3>
    <p>Since the input data is JSON,
we opted to convert it to <a property="http://purl.org/spar/cito/citesAsAuthority" href="http://www.w3.org/TR/json-ld/">JSON-LD</a> <a class="reference" href="#ref-17">[17]</a>,
an RDF syntax specifically designed for adding semantics to JSON.
JSON-LD achieves this by adding a so-called <em>context</em> to the JSON data,
which describes how the JSON tags should be interpreted.
E.g., having <code>"name": "foaf:name"</code> in your context implies
that all name tags should be interpreted as the predicate <code>foaf:name</code>.
Other JSON-LD keywords can be used to identify whether certain values are IRIs,
or whether an entity has a specific type.
For the data where we could not reach the format using just the JSON-LD context,
such as concatenating values to create a IRI,
we modified some of the input JSON before exporting it to JSON-LD.</p>

    <h3 id="bundles">Bundles</h3>
    <p>A bundle represents the general npm package.
An example of a JSON representation of an npm bundle can be found at <a href="https://registry.npmjs.org/n3/" class="iri-link">https:/​/​registry.npmjs.org/n3/</a>.
This contains all the general descriptions that apply to all bundles in this module,
such as the name, homepage and description.</p>

    <p>To adapt this JSON to RDF,
we start by adding our context,
<a href="https://linkedsoftwaredependencies.org/contexts/npm" class="iri-link">https:/​/​linkedsoftwaredependencies.org/contexts/npm</a>,
which already maps many of the npm tags to corresponding RDF predicates.
This allows these tags to remain the same in the JSON-LD representation.
The limitations of context mapping necessitated
some other changes,
the most important one relating to the specific versions of the bundle.
This can be seen by retrieving <a href="https://linkedsoftwaredependencies.org/bundles/npm/n3" class="iri-link">https:/​/​linkedsoftwaredependencies.org/bundles/npm/n3</a> with an <code>Accept: application/ld+json</code> header.
There the bundle now contains links to its corresponding modules,
providing semantic connections between them.
Additionally, some tags were added to provide identifiers and link to the original repository.</p>

    <p>Since JSON-LD is an RDF representation, it can easily be converted to other syntaxes,
of which several are supported by our server,
such as Turtle and N-Triples.
These can be retrieved by sending the corresponding <code>Accept</code> headers.
An example of some of the data generated this way can be seen in <a href="#n3.ttl">Listing 1</a>.</p>

    <figure id="n3.ttl" class="listing">
<pre><code>npm:n3 a doap:Project;
  dcterms:abstract &quot;Lightning fast, asynchronous, streaming...&quot;;
  dcterms:subject &quot;turtle&quot;, &quot;rdf&quot;, &quot;n3&quot;, &quot;streaming&quot;, &quot;asynchronous&quot;;
  spdx:licenseDeclared &lt;https://spdx.org/licenses/MIT.html&gt;;
  doap:release 
    &lt;http://linkedsoftwaredependencies.org/bundles/npm/n3/0.10.0&gt;;
  doap:bug-database &lt;https://github.com/RubenVerborgh/N3.js/issues&gt;;
  doap:homepage &lt;https://github.com/RubenVerborgh/N3.js#readme&gt;;
  doap:name &quot;n3&quot;;
  owl:sameAs &quot;https://www.npmjs.com/package/n3&quot;;
  foaf:maker users:rubenverborgh.
users:rubenverborgh foaf:name &quot;Ruben Verborgh&quot;.
</code></pre>
<figcaption>
        <p><span class="label">Listing 1:</span> This listing shows a partial representation in the Turtle syntax of <a href="https://linkedsoftwaredependencies.org/bundles/npm/n3" class="iri-link">https:/​/​linkedsoftwaredependencies.org/bundles/npm/n3</a>.
Prefixes omitted for brevity.</p>
      </figcaption>
</figure>

    <h3 id="modules">Modules</h3>
    <p>A module is a specific version of a package.
Continuing with the examples shown above,
the JSON metadata of version 0.10.0 of the N3 bundle can be found at
<a href="https://registry.npmjs.org/n3/0.10.0" class="iri-link">https:/​/​registry.npmjs.org/n3/0.10.0</a>,
while the IRI in our namespace is <a href="https://linkedsoftwaredependencies.org/bundles/npm/n3/0.10.0" class="iri-link">https:/​/​linkedsoftwaredependencies.org/bundles/npm/n3/0.10.0</a>.
Similarly, many of the tags are mapped by the context,
while other tags had to be modified to provide more relevant triples.</p>

    <p>An important part of an npm package description are the dependencies
and their semantic versions.
For example, N3 0.10.0 has a dependency on <code>async ^2.0.1</code>.
<code>^2.0.1</code> is a semantic version and corresponds to any version number
of async that has a major version of <code>2</code>.
As can be seen in the JSON-LD,
this async dependency is converted to
<a href="https://linkedsoftwaredependencies.org/bundles/npm/async/%5E2.0.1" class="iri-link">https:/​/​linkedsoftwaredependencies.org/bundles/npm/async/%5E2.0.1</a>,
with <code>%5E</code> being the URL-encoded <code>^</code>.
If accessed, the server detects the highest matching version number
and redirects to that module.
Additionally, the body of the redirect contains the relevant metadata describing this,
which in this case results in the following triple (prefixed for clarity):</p>

    <p><code>
async:\%5E2.0.1 npm:maxSatisfying async:2.4.0.
</code></p>

    <p>Additionally, to support in description which modules are being used on a machine,
we created a <a href="https://github.com/LinkedSoftwareDependencies/node-dependency-parser" class="mandatory" data-link-text="https:/​/​github.com/​LinkedSoftwareDependencies/​node-​dependency-​parser">tool</a>
that outputs the actual dependencies
used by a specific package installation in RDF.
This way the exact installation that was used can be described,
without having to rely on the interpretation of semantic versions which can change over time.</p>

    <h3 id="publication">Publication</h3>
    <p>480,000 npm packages correspond to 174,000,000+ triples when we collect the information from all packages.
Next to the subject pages for each bundle, module and user,
we also publish <a href="https://linkedsoftwaredependencies.org/" class="mandatory" data-link-text="https:/​/​linkedsoftwaredependencies.org/​">all of this data</a> through a <a property="http://purl.org/spar/cito/cites" href="http://linkeddatafragments.org/publications/iswc2014.pdf">Triple Pattern Fragments</a> <a class="reference" href="#ref-18">[18]</a> interface
and as <a property="http://purl.org/spar/cito/cites" href="http://www.imap.websemanticsjournal.org/preprints/index.php/ps/article/viewFile/328/333">HDT</a> <a class="reference" href="#ref-19">[19]</a> and <a property="http://purl.org/spar/cito/cites" href="http://www.w3.org/TR/turtle/">Turtle</a> <a class="reference" href="#ref-20">[20]</a> dumps.
This data is republished daily to stay up-to-date with the available information on npm.
Every day, we collect all triples that are generated by our system in a Turtle file.
After that, we convert this Turtle file to an HDT file.
Finally, this HDT file is loaded into a <a href="https://github.com/LinkedDataFragments/Server.js">TPF server</a> instance,
which allows us to publish this data through a low-cost interface that still enables querying.
Using TPF, <a href="https://query.linkedsoftwaredependencies.org/" class="mandatory" data-link-text="https:/​/​query.linkedsoftwaredependencies.org/​">custom SPARQL queries</a> can be evaluated over this dataset,
such as retrieving all dependencies of a bundle and finding the author of a bundle.</p>

  </section>

  <section id="describing-components">
    <h2>Describing components and their configuration</h2>

    <p>In this section, we introduce the <a href="https://linkedsoftwaredependencies.org/vocabularies/object-oriented"><em>Object-Oriented Components ontology</em></a>
for describing software components and their instantiation in a certain configuration,
and provide an example of its application to JavaScript.
Within this ontology,
we reuse Fowler’s definition of a <a property="http://purl.org/spar/cito/providesQuotationFor" href="https://martinfowler.com/articles/injection.html">software component</a> <a class="reference" href="#ref-14">[14]</a> as a “glob” of software.
The purpose of a component is to provide operations that can be used by other components.
The instantiation of a component can require certain parameters,
just like object-oriented programming (OOP) languages allow constructors to have certain arguments.
In this section, we assume OOP in the broad sense of the word, which only requires <em>classes</em>, <em>objects</em> and <em>constructor parameters</em>.
<a href="#voc-oo-diagram">Fig. 2</a> shows an overview of the ontology.</p>

    <figure id="voc-oo-diagram">
<img src="voc-oo-diagram.svg" alt="[Object-Oriented Components ontology diagram]" />
<figcaption>
        <p><span class="label">Fig. 2:</span> Classes and properties in the <a href="https://linkedsoftwaredependencies.org/vocabularies/object-oriented#" class="mandatory" data-link-text="https:/​/​linkedsoftwaredependencies.org/​vocabularies/​object-​oriented#"><em>Object-Oriented Components</em> ontology</a>,
with as prefix <code>oo</code>.</p>
      </figcaption>
</figure>

    <p>Following <a href="#describing-modules">Section 3</a>, we have defined a <em>module</em> as a collection of components.
Within OOP languages, this can correspond to for example a software library or an application,
which can contain a multitude of components.</p>

    <p>We define component as a <em>subclass</em> of <code>rdfs:Class</code>.
The parameters to construct a component can therefore be defined as an <code>rdfs:Property</code> on a component.
This class structure enables convenient semantic descriptions of components instantiations
through the regular <code>rdf:type</code> predicate.
For instance,
a software module representing a parser
can be described as
<code>ldfs:Datasource:Hdt a oo:Class.</code>,
and a concrete instance is
<code>:myHdtDatasource a ldfs:Datasource:Hdt</code>.</p>

    <p>Several <code>oo:Component</code> subclasses are defined.
An <code>oo:Component</code> can be an <code>oo:Class</code>, which means that it can be instantiated based on parameters.
Each component can refer to its path within a module using the <code>oo:componentPath</code> predicate,
which can for instance be the package name in Java.
All instantiations of <code>oo:Class</code> instances are an <code>oo:Instance</code>.
An <code>oo:Class</code> can also be <code>oo:AbstractClass</code>, which does not allow directly instantiating this component type.
Abstract components can be used to define a set of shared parameters in a common ancestor.
Conforming to the RDF semantics, components can have multiple ancestors, and are indicated using the <code>rdfs:subClassOf</code> predicate.</p>

    <p>The parameters that are used to instantiate an <code>oo:Class</code> to an <code>oo:Instance</code> are of type <code>oo:Parameter</code>.
An <code>oo:Parameter</code> is a <em>subclass</em> of <code>rdfs:Property</code>, which simplifies its usage as an RDF property.
<code>oo:defaultValue</code> allows parameters to have a default value when no other values have been provided:
upon instantiation (<a href="#instantiating">Section 5</a>),
a closed world will be assumed.
The <code>oo:uniqueValue</code> predicate is a flag that can be set to indicate whether or not the parameter can only have a single value.</p>

    <p>The resulting description can be included in the module
(for instance, as a JSON-LD file),
or can be created and referred to externally.
Afterwards, it can be reused by multiple dependents.</p>

    <p><a href="#module-ldf">Listing 2</a> shows a simplified example of the LDF server npm module using the components ontology.
It exposes several components such as an HDT and SPARQL datasource and a QPF server,
each of which can take multiple parameters.
These are provided with a unique identifier and definition,
such that the software configuration can receive a semantic interpretation.
For example,
<a href="#config-ldf">Listing 3</a> illustrates how instances can be created of these component types.</p>

    <figure id="module-ldf" class="listing">
<pre><code>npmd:ldf-server a oo:Module;
    oo:component ldfs:Server:Qpf, ldfs:Datasource:Hdt, ldfs:Datasource:Sparql.
ldfs:Server:Tpf a oo:Class;
    oo:parameter ldfs:datasource, ldfs:port.
ldfs:Datasource a oo:AbstractClass;
    oo:parameter ldfs:Datasource:title.
ldfs:Datasource:Hdt a oo:Class;
    rdfs:subClassOf ldfs:Datasource;
    oo:parameter ldfs:Datasource:Hdt:file.
ldfs:Datasource:Sparql a oo:Class;
    rdfs:subClassOf ldfs:Datasource;
    oo:parameter ldfs:Datasource:Sparql:endpoint.

ldfs:datasource                 a oo:Parameter; rdfs:range ldfs:Datasource.
ldfs:port                       a oo:Parameter; rdfs:range xsd:integer.
ldfs:Datasource:title           a oo:Parameter; rdfs:range xsd:string.
ldfs:Datasource:Hdt:file        a oo:Parameter; rdfs:range ldfs:HdtFile.
ldfs:Datasource:Sparql:endpoint a oo:Parameter; rdfs:range ldfs:SparqlEndpoint.
</code></pre>
<figcaption>
        <p><span class="label">Listing 2:</span> The LDF server module contains, among others, an HDT and SPARQL-based datasource component, which both extend from the abstract datasource component.
The HDT and SPARQL datasource are a classes, which both inherit the title parameter from the abstract datasource.
The HDT datasource takes an HDT file as parameter.
The SPARQL datasource takes a SPARQL endpoint IRI as parameter.</p>
      </figcaption>
</figure>

    <figure id="config-ldf" class="listing">
<pre><code>ex:myServer a ldfs:Server:Qpf;
    ldfs:datasource ex:myHdtDatasource, ex:mySparqlDatasource.
ex:myHdtDatasource a ldfs:Datasource:Hdt;
    ldfs:Datasource:title &quot;A DBpedia 2016 datasource&quot;;
    ldfs:Datasource:Hdt:file &lt;http://example.org/dbpedia-2016.hdt&gt;.
ex:mySparqlDatasource a ldfs:Datasource:Sparql;
    ldfs:Datasource:title &quot;A SPARQL-based DBpedia 2016 datasource&quot;;
    ldfs:Datasource:Sparql:endpoint &lt;http://xample.org/sparql/dbpedia-2016&gt;.
</code></pre>
<figcaption>
        <p><span class="label">Listing 3:</span> <code>ex:myServer</code> is a TPF server which will be loaded with a HDT and SPARQL-based datasource.</p>
      </figcaption>
</figure>

  </section>

  <section id="instantiating">
    <h2>Instantiating component configurations</h2>

    <p>In the previous section, we introduced vocabularies for describing software components and how they can be instantiated.
In this section, we introduce a dependency injection framework based on these component descriptions.
With this, we take semantic software component descriptions to the next level,
we don’t only <em>describe</em> components, but also allow them to be <em>instantiated</em>.</p>

    <h3 id="componentsjs-dependency-injection-framework">Components.js dependency injection framework</h3>
    <p>We have implemented <a href="https://github.com/LinkedSoftwareDependencies/Components.js" class="mandatory" data-link-text="https:/​/​github.com/​LinkedSoftwareDependencies/​Components.js">Components.js</a>,
an open-source dependency injection framework for JavaScript, and made it available on <a href="https://www.npmjs.com/package/lsd-components">npm</a>.
It is able to construct component instances based on declarative component constructions in RDF using the vocabulary introduced in <a href="#describing-components">Section 4</a>.
It accepts raw triple streams or URLs to RDF documents containing these declarations.
At the time of writing, the parser accepts RDF documents serialized as either JSON-LD, Turtle, TriG, N-Triples or N-Quads.</p>

    <p><a href="#components.js">Listing 4</a> illustrates how components can be instantiated using Components.js.
It provides a <code>Loader</code> class that acts as an assembler.
This <code>Loader</code> provides <em>constructor injection</em>:
it dynamically calls the constructor of the component and passes the configured parameters in a single object argument.
Additionally, <a href="https://github.com/LinkedSoftwareDependencies/Components.js#configuring-a-component-unnamed">simplified mechanisms</a>
are in place for developers that want to use the dependency injector directly without having to semantically describe the component.</p>

    <figure id="components.js" class="listing">
<pre><code>const loader = new require(&#39;lsd-components&#39;).Loader();
loader.registerConfig(&#39;http://example.org/my-ldf-server&#39;);
let myParser = loader.instantiate(&#39;http://example.org/config-ldf#myServer&#39;);
</code></pre>
<figcaption>
        <p><span class="label">Listing 4:</span> First, a new component loader is created
after which the component definitions are registered.
Finally, a declarative component instantiation is supplied by providing the component IRI
and the location at which the resource can be found.</p>
      </figcaption>
</figure>

    <p>While Linked Data is based on the open-world assumption, our dependency injector will close the world when we enter the realm of OOP.
This is because a close-world assumption is required for features such as default arguments:
we have to assume that all the arguments that are available to the loader is everything there is.</p>

    <h3 id="defining-object-mappings">Defining object mappings</h3>
    <p>The constructor injection described above works out of the box
with single-argument constructors that accept a map,
as is quite common in JavaScript.
Components.js then creates a map with key/value pairs
with the property IRIs and corresponding objects
of all triples with the instance as subject.
This map is then passed to the constructor,
which reads its settings from the map.
Depending on a flag,
the keys and values are either full IRIs
or abbreviated JSON-LD strings.</p>

    <p>New libraries that use Components.js
can be designed for such single-parameter constructors.
For all other types constructors,
a mapping mechanism is needed
between the RDF properties
and the concrete parameter order of the constructor.
To this end, we introduce the <a href="https://linkedsoftwaredependencies.org/vocabularies/object-mapping"><em>Object Mapping ontology</em></a>.
<a href="#voc-om-diagram">Fig. 3</a> shows an overview of all its classes and predicates.</p>

    <figure id="voc-om-diagram">
<img src="voc-om-diagram.svg" alt="[Object Mapping ontology diagram]" />
<figcaption>
        <p><span class="label">Fig. 3:</span> Overview of the classes and properties in the <em>Object Mapping</em> ontology, with as prefix <a href="https://linkedsoftwaredependencies.org/vocabularies/object-mapping#" class="mandatory" data-link-text="https:/​/​linkedsoftwaredependencies.org/​vocabularies/​object-​mapping#"><code>om</code></a>.</p>
      </figcaption>
</figure>

    <p>The ontology introduces the <em>object mapping</em> and the <em>array mapping</em>.
An object map can have several <em>object mapping entries</em>, where each entry has a field name and a field value.
An array map can have several <em>array mapping entries</em>, where each entry only has a value.
Together, they can express all ways
in which the flat object from the RDF description
maps to an ordered list of simple or complex constructor parameters.</p>

    <p><a href="#module-ldf-mapped">Listing 5</a> shows the mapping of the LDF component parameters to the constructor implementation.
This description complements the component definitions from <a href="#module-ldf">Listing 2</a>
as it provides an implementation view on the component constructors.
Like the component definitions,
a mapping is only necessary once per module
and can be reused across dependents.</p>

    <figure id="module-ldf-mapped" class="listing">
<pre><code>ldfs:Server:Tpf oo:constructorArguments ([ om:field
  [ om:fieldName &quot;datasources&quot;; om:fieldValue
      [ om:fieldName ldfs:Datasource:title, om:fieldValue rdf:object ] ],
  [ om:fieldName &quot;port&quot;; om:fieldValue: ldfs:port ].
]).
ldfs:Datasource:Hdt oo:constructorArguments ([ om:field
  [ om:fieldName &quot;title&quot;; om:fieldValue: ldfs:Datasource:title ],
  [ om:fieldName &quot;file&quot;;  om:fieldValue: ldfs:Datasource:Hdt:file ].
]).
ldfs:Datasource:Sparql oo:constructorArguments ([ om:field
  [ om:fieldName &quot;title&quot;;    om:fieldValue: ldfs:Datasource:title ],
  [ om:fieldName &quot;endpoint&quot;; om:fieldValue: ldfs:Datasource:Sparql:endpoint ].
]).
</code></pre>
<figcaption>
        <p><span class="label">Listing 5:</span> The HDT and SPARQL-based datasource constructors both take a custom object as argument for the constructor.
The entries of this object are mapped from the parameter values using this mapping.
The TPF server constructor similarly requires a custom object,
where the <code>datasources</code> entry points to an object that is a mapping from titles to datasources.</p>
      </figcaption>
</figure>

  </section>

  <section id="use-case">
    <h2>Use case: describing a Linked Data Fragments experiment</h2>

    <p>In this section, we provide a semantic description
of the experiment performed in a previous research article,
as a guiding example
on how to create such descriptions for other evaluations.
The intention is that future research articles
directly describe their experimental setup this way,
either through HTML with embedded RDFa
or as a reference to an IRI of an RDF document.</p>

    <p>This experiment we will describe
originates from <a property="http://purl.org/spar/cito/citesAsAuthority" href="http://linkeddatafragments.org/publications/iswc2014.pdf">an ISWC2014 article</a> <a class="reference" href="#ref-18">[18]</a>
and involves specific software configurations
of a Linked Data Fragments (LDF) client and server.
We have semantically described the <a href="https://github.com/LinkedDataFragments/Server.js/tree/feature-lsd">LDF server</a> module and its 32 components.
Instead of the former domain-specific <a href="https://github.com/LinkedDataFragments/Server.js/blob/master/config/config-example.json">JSON configuration file</a>,
the <a href="https://github.com/LinkedDataFragments/Server.js/blob/feature-lsd/config/config-example.json">semantic configuration</a> is Linked Data
and can be instantiated automatically by Components.js.
Furthermore, we provide an automatically generated semantic description
of all concrete installed dependency versions
for both the LDF client and server.
This is necessary because,
as discussed in <a href="#modules">Subsection 3.4</a>,
modules indicate a compatibility range
instead of a concrete version.</p>

    <p>The ISWC2014 LDF experiment can be described using the following <a about="#ldf-2014-qdwha-experiment-workflow" content="LDF 2014 experiment workflow" href="#ldf-2014-qdwha-experiment-workflow" property="rdfs:label" rel="cc:license" resource="https://creativecommons.org/licenses/by/4.0/">workflow</a>:</p>

    <!-- TODO:
  Define (elsewhere) and reuse an actual IRI Template for the workflow and steps
  i.e., preferrably not relative to this document.
  Change "#ldf-2014-qdwha-" to something else that is machine-generated and
  determinstic. More specific to the operation and independent to the article it
  was used in.

-->

    <ol id="ldf-2014-qdwha-experiment-workflow" property="schema:hasPart" resource="#ldf-2014-qdwha-experiment-workflow" typeof="opmw:WorkflowTemplate">
<li id="ldf-2014-qdwha-experiment-create-vm-for-server" about="#ldf-2014-qdwha-experiment-create-vm-for-server" typeof="opmw:WorkflowTemplateProcess" rel="opmw:isStepOfTemplate" resource="#ldf-2014-qdwha-experiment-workflow" property="rdfs:label">Create 1 virtual machine for the server.</li>
<li id="ldf-2014-qdwha-experiment-create-vm-for-cache" about="#ldf-2014-qdwha-experiment-create-for-cache" typeof="opmw:WorkflowTemplateProcess" rel="opmw:isStepOfTemplate" resource="#ldf-2014-qdwha-experiment-workflow" property="rdfs:label">Create 1 virtual machine for a cache.</li>
<li id="ldf-2014-qdwha-experiment-create-60-vm-for-clients" about="#ldf-2014-qdwha-experiment-create-60-vm-for-clients" typeof="opmw:WorkflowTemplateProcess" rel="opmw:isStepOfTemplate" resource="#ldf-2014-qdwha-experiment-workflow" property="rdfs:label">Create 60 virtual machines for clients.</li>
<li id="ldf-2014-qdwha-experiment-copy-generated-bsbm-dataset-to-server" about="#ldf-2014-qdwha-experiment-copy-generated-bsbm-dataset-to-server" typeof="opmw:WorkflowTemplateProcess" rel="opmw:isStepOfTemplate" resource="#ldf-2014-qdwha-experiment-workflow" property="rdfs:label">Copy a generated <a property="http://purl.org/spar/cito/cites" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.161.8030&amp;rep=rep1&amp;type=pdf">Berlin SPARQL benchmark</a> <a class="reference" href="#ref-21">[21]</a> <a href="http://wifo5-03.informatik.uni-mannheim.de/bizer/berlinsparqlbenchmark/spec/Dataset/index.html">dataset</a> to the server.</li>
<li id="ldf-2014-qdwha-experiment-install-server-software-config-with-tpf-spec" about="#ldf-2014-qdwha-experiment-install-server-software-config-with-tpf-spec" typeof="opmw:WorkflowTemplateProcess" rel="opmw:isStepOfTemplate" resource="#ldf-2014-qdwha-experiment-workflow" property="rdfs:label">
        <p>Install <a href="https://linkedsoftwaredependencies.org/raw/ldf-availability-experiment-config.jsonld" class="mandatory" data-link-text="https:/​/​linkedsoftwaredependencies.org/​raw/​ldf-​availability-​experiment-​config.jsonld">the server software configuration</a>, implementing the <a href="https://www.hydra-cg.com/spec/latest/triple-pattern-fragments/" class="mandatory" data-link-text="https:/​/​www.hydra-​cg.com/​spec/​latest/​triple-​pattern-​fragments/​">TPF specification</a>, with its <a href="https://linkedsoftwaredependencies.org/raw/ldf-availability-experiment-setup.ttl">dependencies</a> on the server.</p>
      </li>
<li id="ldf-2014-qdwha-experiment-install-client-software-config-with-sparql" about="#ldf-2014-qdwha-experiment-client-software-config-with-sparql" typeof="opmw:WorkflowTemplateProcess" rel="opmw:isStepOfTemplate" resource="#ldf-2014-qdwha-experiment-workflow" property="rdfs:label">
        <p>Install <a href="https://github.com/LinkedDataFragments/Client.js" class="mandatory" data-link-text="https:/​/​github.com/​LinkedDataFragments/​Client.js">the client software configuration</a>, implementing the <a href="https://www.w3.org/TR/sparql11-protocol">SPARQL 1.1 protocol</a>, with its <a href="https://linkedsoftwaredependencies.org/raw/ldf-availability-experiment-client.ttl" class="mandatory" data-link-text="https:/​/​linkedsoftwaredependencies.org/​raw/​ldf-​availability-​experiment-​client.ttl">dependencies</a> on each client.</p>
      </li>
<li id="ldf-2014-qdwha-experiment-execute-bsbm-per-client" about="#ldf-2014-qdwha-experiment-bsbm-per-client" typeof="opmw:WorkflowTemplateProcess" rel="opmw:isStepOfTemplate" resource="#ldf-2014-qdwha-experiment-workflow" property="rdfs:label">Execute four processes of the <a property="http://purl.org/spar/cito/cites" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.161.8030&amp;rep=rep1&amp;type=pdf">Berlin SPARQL benchmark</a> <a class="reference" href="#ref-21">[21]</a> with the client software for each client machine</li>
<li id="ldf-2014-qdwha-experiment-record-cpu-ram-client-server-io-cache" about="#ldf-2014-qdwha-experiment-record-cpu-ram-client-server-io-cache" typeof="opmw:WorkflowTemplateProcess" rel="opmw:isStepOfTemplate" resource="#ldf-2014-qdwha-experiment-workflow" property="rdfs:label">Record CPU time, RAM usage of each client, the CPU time and RAM usage of the server, and measure the ingoing and outgoing bandwidth of the cache.</li>
<li id="ldf-2014-qdwha-experiment-publish-results" about="#ldf-2014-qdwha-experiment-publish-results" typeof="opmw:WorkflowTemplateProcess" rel="opmw:isStepOfTemplate" resource="#ldf-2014-qdwha-experiment-workflow" property="rdfs:label">Publish <a href="http://data.linkeddatafragments.org/benchmark">results</a> online.</li>
</ol>

    <p>An <em>executed</em> workflow corresponding to the <em>abstract</em> experiment workflow above
generates entities based on each activity as performed by various agents.
Essentially the resulting observations of the experiment are
among other valuable immutable provenance level data which plays a vital role in
verifying and reproducing the steps which led to the outcome.
Concretely, the conclusions in the article
have the resulting data as provenance,
which in turn was generated by applying the steps above.</p>

    <p>Crucially, in the description above,
we refer to the exact software configurations by their IRI,
their specific dependency versions,
and the specifications they implement.
These serve as further documentation of the provenance.
Additionally, based on these IRIs,
other researchers can immediately instantiate the same configuration,
or derive their own similar configurations
to create comparative experiments.
While software container solutions (such as <a href="https://www.docker.com/">Docker</a>)
could also provide immediate instantiation,
their configuration is on a much higher level.
Instead, the Object-Oriented Components ontology
captures the low-level wiring between components,
enabling researchers to swap individual algorithms
or component settings.</p>

    <p>For example, based on the above description,
the exact same experiment can be performed
with <a property="http://purl.org/spar/cito/obtainsBackgroundFrom" href="http://linkeddatafragments.org/publications/eswc2015.pdf">different client-side algorithms</a> <a class="reference" href="#ref-22">[22]</a>
or <a property="http://purl.org/spar/cito/obtainsBackgroundFrom" href="https://arxiv.org/pdf/1608.08148.pdf">different server-side interfaces</a> <a class="reference" href="#ref-23">[23]</a>.
A common practice to achieve this currently,
as done in the aforementioned works <a class="reference" href="#ref-22">[22]</a><a class="reference" href="#ref-23">[23]</a>,
is to implement modifications in separate code repository branches.
Unfortunately,
such branches typically diverge from the main code tree,
and hence cannot easily be evaluated afterwards
with later versions of other components.
By implementing them as independent modules instead,
they can be plugged in automatically
by minimally altering the declarative experiment description.
This simultaneously records their provenance,
enables their automated instantiation,
and ensures their sustainability.</p>

  </section>

  <section id="conclusion">
    <h2>Conclusion</h2>

    <p>The core idea of the scientific process is <em>to stand on the shoulders of giants</em>.
This means building further upon previous work to derive new work—but
also, enabling others to build upon our work.
Reproducibility, for instance, is an essential aspect of this process.
Not only does this concept apply to Web research as well,
but the Web makes an ideal platform to <em>improve</em> the scientific process as a whole.</p>

    <p>In this article, we introduce vocabularies for semantically describing software components and their configuration.
Publishing this information alongside experimental results is beneficial for the reproduction of experiments.
Furthermore, we introduce Components.js, a dependency injection framework that can <em>understand</em> such configurations,
and <em>instantiate</em> software in the exact same way as originally described.</p>

    <p>In future work, we aim to make the creation of semantic component files more developer-friendly.
A tool can automatically parse source code
and derive the appropriate semantic description on how components can be instantiated using which parameters.
Additionally, these semantic component definition files provide an interesting platform for validating software dependency relations.
Reasoning could for instance be done on parameter restrictions to check whether
or not different bundle versions will break certain component invocations.
Furthermore, the semantic description of software metadata provides a useful platform for simplifying tasks that require a lot manual work,
such as discovering license incompatibilities between projects, which are now possible using a <a href="https://query.linkedsoftwaredependencies.org/#query=SELECT%20*%20WHERE%20%7B%0A%20%20%3Fbundle%20spdx%3AlicenseDeclared%20%3Chttps%3A%2F%2Fspdx.org%2Flicenses%2FGPL-3.0.html%3E.%0A%20%20%3Fbundle%20npm%3Adependency%20%3Fdependency.%0A%20%20%3Fdependency%20spdx%3AlicenseDeclared%20%3Chttps%3A%2F%2Fspdx.org%2Flicenses%2FGPL-2.0.html%3E.%0A%7D">SPARQL query</a>.
This even allows us to come up with SPARQL queries corresponding to some of the questions
that <a property="http://purl.org/spar/cito/citesForInformation" href="https://www.w3.org/History/1989/proposal.html">the Web was intended to give an answer for</a> <a class="reference" href="#ref-3">[3]</a>,
such as <q><a href="https://query.linkedsoftwaredependencies.org/#query=SELECT%20DISTINCT%20%3Fproject%20%3FprojectName%20%3Fdescription%20WHERE%20%7B%0A%20%20%3Chttps%3A%2F%2Flinkedsoftwaredependencies.org%2Fbundles%2Fnpm%2Fn3%3E%20doap%3Arelease%20%3Fversion.%0A%20%20%3Fdependingversion%20npm%3Adependency%20%3Fversion.%0A%20%20%3Fproject%20doap%3Arelease%20%3Fdependingversion.%0A%20%20%3Fproject%20doap%3Aname%20%3FprojectName.%0A%20%20%3Fproject%20dc%3Aabstract%20%3Fdescription.%0A%7D">Where is this module used?</a></q> and <q><a href="https://query.linkedsoftwaredependencies.org/#query=SELECT%20*%20WHERE%20%7B%0A%20%20%3Chttps%3A%2F%2Flinkedsoftwaredependencies.org%2Fbundles%2Fnpm%2Fn3%3E%20doap%3Amaintainer%20%3Fauthor.%0A%20%20%3Fauthor%20foaf%3Aname%20%3Fname.%0A%20%20%3Fauthor%20foaf%3Ambox%20%3Fmail.%0A%7D">Who wrote this code?</a></q>.</p>

    <p>Through this work, we make it easier to build sustainable research platforms,
which helps pave the stairs to the shoulders of giants.
Our Linked Data Fragments server, for instance, is a reusable research platform.
The LDF server and client can be compatible with multiple APIs, have multiple algorithms, etc.
Through this work, only one “core version” is necessary, and many different configurations can co-exist,
where support for different APIs and algorithms are simply pluggable components that are referred to within a configuration.
Since components and configurations are identified by a IRI,
they can exist anywhere on the Web.
Based on a IRI, the injection framework can therefore instantiate software,
and wire its dependent components together automatically.
We thereby leveraging the power of the Web to simplify the reproduction of existing experiments
and the creation of new ones.</p>

  </section>

</main>

<footer>
<section id="references">
<h2>References</h2>
<dl class="references">
  <dt id="ref-1">[1]</dt>
  <dd>Buckheit, J.B., Donoho, D.L.: WaveLab and Reproducible Research. Stanford University (1995).</dd>
  <dt id="ref-2">[2]</dt>
  <dd>Berners-Lee, T.: Linked Data, <a href="https://www.w3.org/DesignIssues/LinkedData.html,">https:/​/​www.w3.org/DesignIssues/LinkedData.html,</a> (2009).</dd>
  <dt id="ref-3">[3]</dt>
  <dd>Berners-Lee, T.: Information Management: A Proposal, <a href="https://www.w3.org/History/1989/proposal.html,">https:/​/​www.w3.org/History/1989/proposal.html,</a> (1989).</dd>
  <dt id="ref-4">[4]</dt>
  <dd>Banati, A., Kacsuk, P., Kozlovszky, M.: Four level provenance support to achieve portable reproducibility of scientific workflows. In: 38th International Convention on Information and Communication Technology,  Electronics and Microelectronics (MIPRO). IEEE (2015).</dd>
  <dt id="ref-5">[5]</dt>
  <dd>Rietveld, L., Beek, W., Schlobach, S.: LOD Lab: Experiments at LOD Scale. In: Arenas, M., Corcho, O., Simperl, E., Strohmaier, M., d’Aquin, M., Srinivas, K., Groth, P., Dumontier, M., Heflin, J., Thirunarayan, K., and Staab, S. (eds.) Proceedings of the 14th International Semantic Web Conference. pp. 339–355. Springer (2015).</dd>
  <dt id="ref-6">[6]</dt>
  <dd>Lebo, T., Sahoo, S., McGuinness, D.: Prov-O: The PROV Ontology. W3C (2013).</dd>
  <dt id="ref-7">[7]</dt>
  <dd>Garijo, D., Gil, Y.: The OPMW-PROV Ontology. (2014).</dd>
  <dt id="ref-8">[8]</dt>
  <dd>Garijo, D., Gil, Y.: The P-PLAN Ontology. (2014).</dd>
  <dt id="ref-9">[9]</dt>
  <dd>Lebo, T., Sahoo, S., McGuinness, D.: The RDF Data Cube Vocabulary. W3C (2014).</dd>
  <dt id="ref-10">[10]</dt>
  <dd>Bosch, T., Cyganiak, R., Wackerow, J., Zapilko, B.: DDI-RDF Discovery Vocabulary. (2015).</dd>
  <dt id="ref-11">[11]</dt>
  <dd>Belhajjame, K., Zhao, J., Garijo, D., Gamble, M., Hettne, K., Palma, R., Mina, E., Corcho, O., Gómez-Pérez, J.M., Bechhofer, S., Klyne, G., Goble, C.: Using a suite of ontologies for preserving workflow-centric research objects. Web Semantics: Science,  Services and Agents on the World Wide Web. 32, 16–42 (2015).</dd>
  <dt id="ref-12">[12]</dt>
  <dd>Rautenberg, S., Ermilov, I., Marx, E., Auer, S., Ngonga Ngomo, A.-C.: LODFlow: A Workflow Management System for Linked Data Processing. In: Proceedings of the 11th International Conference on Semantic Systems. pp. 137–144. ACM, New York, NY, USA (2015).</dd>
  <dt id="ref-13">[13]</dt>
  <dd>Mens, T., Wermelinger, M.: Separation of Concerns for Software Evolution. Journal of Software Maintenance. 14, 311–315 (2002).</dd>
  <dt id="ref-14">[14]</dt>
  <dd>Fowler, M.: Inversion of Control Containers and the Dependency Injection pattern, <a href="https://martinfowler.com/articles/injection.html,">https:/​/​martinfowler.com/articles/injection.html,</a> (2004).</dd>
  <dt id="ref-15">[15]</dt>
  <dd>Fowler, M.: Inversion Of Control, <a href="https://martinfowler.com/bliki/InversionOfControl.html,">https:/​/​martinfowler.com/bliki/InversionOfControl.html,</a> (2005).</dd>
  <dt id="ref-16">[16]</dt>
  <dd>Johnson, R.E., Foote, B.: Designing reusable classes. Journal of object-oriented programming. 1, 22–35 (1988).</dd>
  <dt id="ref-17">[17]</dt>
  <dd>Sporny, M., Longley, D., Kellogg, G., Lanthaler, M., Lindström, N.: JSON-LD 1.0. World Wide Web Consortium (2014).</dd>
  <dt id="ref-18">[18]</dt>
  <dd>Verborgh, R., Hartig, O., De Meester, B., Haesendonck, G., De Vocht, L., Vander Sande, M., Cyganiak, R., Colpaert, P., Mannens, E., Walle, R. Van de: Querying Datasets on the Web with High Availability. In: Mika, P., Tudorache, T., Bernstein, A., Welty, C., Knoblock, C., Vrandečić, D., Groth, P., Noy, N., Janowicz, K., and Goble, C. (eds.) Proceedings of the 13th International Semantic Web Conference. pp. 180–196. Springer (2014).</dd>
  <dt id="ref-19">[19]</dt>
  <dd>Fernández, J.D., Martínez-Prieto, M.A., Gutiérrez, C., Polleres, A., Arias, M.: Binary RDF representation for publication and exchange (HDT). Web Semantics: Science, Services and Agents on the World Wide Web. 19, 22–41 (2013).</dd>
  <dt id="ref-20">[20]</dt>
  <dd>Beckett, D., Berners-Lee, T., Prud’hommeaux, E., Carothers, G.: RDF 1.1 Turtle. W3C (2014).</dd>
  <dt id="ref-21">[21]</dt>
  <dd>Bizer, C., Schultz, A.: The Berlin SPARQL benchmark. International journal on Semantic Web and information systems. 5, 1–24 (2009).</dd>
  <dt id="ref-22">[22]</dt>
  <dd>Van Herwegen, J., Verborgh, R., Mannens, E., Walle, R. Van de: Query Execution Optimization for Clients of Triple Pattern Fragments. In: Gandon, F., Sabou, M., Sack, H., d’Amato, C., Cudré-Mauroux, P., and Zimmermann, A. (eds.) The Semantic Web. Latest Advances and New Domains. pp. 302–318 (2015).</dd>
  <dt id="ref-23">[23]</dt>
  <dd>Hartig, O., Buil-Aranda, C.: Bindings-Restricted Triple Pattern Fragments. In: Debruyne, C., Panetto, H., Meersman, R., Dillon, T., Kühn, eva, O’Sullivan, D., and Ardagna, C.A. (eds.) Proceedings of the 15th International Conference on Ontologies, DataBases, and Applications of Semantics. pp. 762–779. Springer (2016).</dd>
</dl>
</section>
</footer>



</body>
</html>
